{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56547.75 37200.15\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "#1. Загрузите данные об описаниях вакансий и соответствующих годовых зарплатах из файла salary-train.csv \n",
    "data = pd.read_csv('salary-train.csv')\n",
    "\n",
    "#2. Проведите предобработку:\n",
    "def transform(text):\n",
    "    #Приведите тексты к нижнему регистру (text.lower()).\n",
    "    text = text.map(lambda x: x.lower())\n",
    "    #Замените все, кроме букв и цифр, на пробелы — это облегчит дальнейшее разделение текста на слова. \n",
    "    text = text.replace('[^a-zA-Z0-9]',regex = True)\n",
    "    return text\n",
    "#Примените TfidfVectorizer для преобразования текстов в векторы признаков. Оставьте только те слова,\n",
    "#которые встречаются хотя бы в 5 объектах (параметр min_df у TfidfVectorizer).\n",
    "vectorizer = TfidfVectorizer(min_df = 5)\n",
    "x_train_data = vectorizer.fit_transform(transform(data['FullDescription']))\n",
    "\n",
    "#Замените пропуски в столбцах LocationNormalized и ContractTime на специальную строку 'nan'.\n",
    "data['LocationNormalized'].fillna('nan', inplace = True)\n",
    "data['ContractTime'].fillna('nan', inplace = True)\n",
    "\n",
    "#Примените DictVectorizer для получения one-hot-кодирования признаков LocationNormalized и ContractTime.\n",
    "enc = DictVectorizer()\n",
    "x_train_categ = enc.fit_transform(data[['LocationNormalized', 'ContractTime']].to_dict('records'))\n",
    "\n",
    "#Объедините все полученные признаки в одну матрицу \"объекты-признаки\". Для объединения их столбцов \n",
    "#нужно воспользоваться функцией scipy.sparse.hstack.\n",
    "\n",
    "x_train = hstack([x_train_data,x_train_categ])\n",
    "\n",
    "#3. Обучите гребневую регрессию с параметрами alpha=1 и random_state=241. Целевая переменная \n",
    "#записана в столбце SalaryNormalized.\n",
    "\n",
    "y_train = data['SalaryNormalized']\n",
    "model = Ridge(alpha = 1, random_state = 241)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "#4. Постройте прогнозы для двух примеров из файла salary-test-mini.csv. Значения полученных прогнозов \n",
    "#являются ответом на задание. Укажите их через пробел.\n",
    "\n",
    "test = pd.read_csv('salary-test-mini.csv')\n",
    "x_test_text = vectorizer.transform(transform(test['FullDescription']))\n",
    "x_test_categ = enc.transform(test[['LocationNormalized', 'ContractTime']].to_dict('records'))\n",
    "x_test = hstack([x_test_text, x_test_categ])\n",
    "\n",
    "y_test = model.predict(x_test)\n",
    "print(round(y_test[0],2), round(y_test[1],2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
